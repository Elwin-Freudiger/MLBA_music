added_by             = `Added By`,
added_at             = `Added At`,
artist_genres        = `Artist Genres`,
danceability         = `Danceability`,
energy               = `Energy`,
key                  = `Key`,
loudness             = `Loudness`,
mode                 = `Mode`,
speechiness          = `Speechiness`,
acousticness         = `Acousticness`,
instrumentalness     = `Instrumentalness`,
liveness             = `Liveness`,
valence              = `Valence`,
tempo                = `Tempo`,
time_signature       = `Time Signature`,
album_genres         = `Album Genres`,
label                = `Label`,
copyrights           = `Copyrights`
)
spotify_vr <- spotify |>
select(-artist_uris, -album_uri,-album_artist_uris,-album_artist_names, -disc_number,-preview_url, -isrc, -added_by, -added_at, -album_genres, -copyrights,-key)
ncol(spotify_vr)
# Count total missing values
sum(is.na(spotify_vr))  # This will return the total number of NAs
# Show missing values per column
colSums(is.na(spotify_vr))
#Rows with missing values
rows_with_missing <- spotify_vr |>
filter(if_any(everything(), ~ is.na(.) | . == ""))
# View the rows
rows_with_missing
spotify_clean <- spotify_vr |>
filter(!is.na(loudness) & loudness != "")
colSums(is.na(spotify_clean))
spotify_dec <- spotify_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec %>%
count(decade, sort = TRUE)
spotify_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced |>
select(all_of(features), decade_group) |>
rename(decade = decade_group) |>
mutate(decade = as.factor(decade)) |>
na.omit()
split <- initial_split(df, prop = 0.8, strata = decade)
train <- training(split)
test <- testing(split)
# Fit model
rf_model <- randomForest(decade ~ ., data = train)
# Predict
pred <- predict(rf_model, newdata = test)
# Accuracy
mean(pred == test$decade)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$decade)
print(accuracy)
# Confusion Matrix
confusionMatrix(pred, test$decade)
spotify_clean <- spotify_clean |>
mutate(year = as.numeric(substr(release_date, 1, 4)))
# Calculate and display the median
median_year <- median(spotify_dec$year, na.rm = TRUE)
print(median_year)
spotify_binary <- spotify_clean |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_binary |>
select(all_of(features), after_median) |>
na.omit()
set.seed(123)
train_idx <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train <- df[train_idx, ]
test <- df[-train_idx, ]
rf_model <- randomForest(after_median ~ ., data = train, ntree = 500)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$after_median)
print(accuracy)
# Confusion Matrix
library(caret)
confusionMatrix(pred, test$after_median)
spotify_dec <- dataset_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
#| echo: false
#| message: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(broom)
library(reshape2)
library(magrittr)
library(corrplot)
library(plotly)
library(ggcorrplot)
library(factoextra)
library(FactoMineR)
library(dplyr)
library(ggplot2)
library(corrplot)
library(randomForest)
library(rpart)
library(rpart.plot)
library(lubridate)
library(caret)
library(rsample)
#| echo: false
library(readr)
spotify <- read_csv("~/ML project/top_10000_1950-now.csv")
#spotify <- read_csv("top_10000_1950-now.csv")
#| echo: false
# Preview the dataset
knitr::kable(head(spotify),
format = "markdown",
align = 'c',
table.attr = 'class="table table-bordered"',
row.names = FALSE) %>%
kable_styling(font_size = 10, full_width = FALSE, position = "center")
spotify <- spotify |>
rename(
track_uri            = `Track URI`,
track_name           = `Track Name`,
artist_uris          = `Artist URI(s)`,
artist_names         = `Artist Name(s)`,
album_uri            = `Album URI`,
album_name           = `Album Name`,
album_artist_uris    = `Album Artist URI(s)`,
album_artist_names   = `Album Artist Name(s)`,
release_date         = `Album Release Date`,
album_image_url      = `Album Image URL`,
disc_number          = `Disc Number`,
track_number         = `Track Number`,
duration_ms          = `Track Duration (ms)`,
preview_url          = `Track Preview URL`,
is_explicit          = `Explicit`,
popularity           = `Popularity`,
isrc                 = `ISRC`,
added_by             = `Added By`,
added_at             = `Added At`,
artist_genres        = `Artist Genres`,
danceability         = `Danceability`,
energy               = `Energy`,
key                  = `Key`,
loudness             = `Loudness`,
mode                 = `Mode`,
speechiness          = `Speechiness`,
acousticness         = `Acousticness`,
instrumentalness     = `Instrumentalness`,
liveness             = `Liveness`,
valence              = `Valence`,
tempo                = `Tempo`,
time_signature       = `Time Signature`,
album_genres         = `Album Genres`,
label                = `Label`,
copyrights           = `Copyrights`
)
library(dplyr)
library(stringr)
spotify_vr <- spotify_vr |>
mutate(track_uri = str_extract(track_uri, "[^:]+$"))
#| echo: false
# Preview the dataset
knitr::kable(head(spotify_vr),
format = "markdown",
align = 'c',
table.attr = 'class="table table-bordered"',
row.names = FALSE) %>%
kable_styling(font_size = 10, full_width = FALSE, position = "center")
# Count total missing values
sum(is.na(spotify_vr))  # This will return the total number of NAs
# Show missing values per column
colSums(is.na(spotify_vr))
#Rows with missing values
rows_with_missing <- spotify_vr |>
filter(if_any(everything(), ~ is.na(.) | . == ""))
# View the rows
rows_with_missing
dataset_clean <- spotify_vr |>
filter(!is.na(loudness) & loudness != "") %>%
mutate(release_year = as.numeric(substr(release_date, start = 1, stop = 4)))
colSums(is.na(dataset_clean))
numeric_data <- dataset_clean %>% select(where(is.numeric)) |>
select(-mode,-time_signature)
long_data <- pivot_longer(numeric_data, cols = everything(), names_to = "Variable", values_to = "Value")
# Faceted boxplots with individual y-axis scales
ggplot(long_data, aes(x = "", y = Value)) +
geom_boxplot() +
facet_wrap(~ Variable, scales = "free_y") +
labs(title = "Boxplots for Numeric Variables (Individual Scales)", x = "", y = "") +
theme_minimal()
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
spotify_dec <- spotify_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec %>%
count(decade, sort = TRUE)
spotify_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced |>
select(all_of(features), decade_group) |>
rename(decade = decade_group) |>
mutate(decade = as.factor(decade)) |>
na.omit()
split <- initial_split(df, prop = 0.8, strata = decade)
train <- training(split)
test <- testing(split)
# Fit model
rf_model <- randomForest(decade ~ ., data = train)
# Predict
pred <- predict(rf_model, newdata = test)
# Accuracy
mean(pred == test$decade)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$decade)
print(accuracy)
# Confusion Matrix
confusionMatrix(pred, test$decade)
View(spotify_dec)
View(spotify_dec)
View(spotify_dec)
dataset_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced |>
select(all_of(features), decade_group) |>
rename(decade = decade_group) |>
mutate(decade = as.factor(decade)) |>
na.omit()
split <- initial_split(df, prop = 0.8, strata = decade)
train <- training(split)
test <- testing(split)
# Fit model
rf_model <- randomForest(decade ~ ., data = train)
# Predict
pred <- predict(rf_model, newdata = test)
# Accuracy
mean(pred == test$decade)
View(df)
View(df)
#| echo: false
#| message: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(broom)
library(reshape2)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(magrittr)
library(corrplot)
library(plotly)
library(randomForest)
library(rpart)
library(rpart.plot)
library(lubridate)
library(caret)
library(rsample)
spotify_dec <- dataset_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec %>%
count(decade, sort = TRUE)
dataset_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced |>
select(all_of(features), decade_group) |>
rename(decade = decade_group) |>
mutate(decade = as.factor(decade)) |>
na.omit()
split <- initial_split(df, prop = 0.8, strata = decade)
train <- training(split)
test <- testing(split)
# Fit model
rf_model <- randomForest(decade ~ ., data = train)
# Predict
pred <- predict(rf_model, newdata = test)
# Accuracy
mean(pred == test$decade)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$decade)
print(accuracy)
# Confusion Matrix
confusionMatrix(pred, test$decade)
spotify_clean <- dataset_clean |>
mutate(year = as.numeric(substr(release_date, 1, 4)))
# Calculate and display the median
median_year <- median(spotify_dec$year, na.rm = TRUE)
print(median_year)
spotify_binary <- spotify_clean |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_binary |>
select(all_of(features), after_median) |>
na.omit()
View(spotify_balanced)
spotify_clean <- dataset_clean |>
mutate(year = as.numeric(substr(release_date, 1, 4)))
# Calculate and display the median
median_year <- median(spotify_dec$year, na.rm = TRUE)
print(median_year)
spotify_binary <- spotify_clean |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_binary |>
select(all_of(features), after_median) |>
na.omit()
set.seed(123)
train_idx <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train <- df[train_idx, ]
test <- df[-train_idx, ]
rf_model <- randomForest(after_median ~ ., data = train, ntree = 500)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$after_median)
print(accuracy)
# Confusion Matrix
library(caret)
confusionMatrix(pred, test$after_median)
# Summary statistics for key numeric features
dataset_clean %>%
select_if(is.numeric) %>%
summary() %>%
kable() %>%
kable_styling()
spotify_dec <- dataset_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec %>%
count(decade, sort = TRUE)
spotify_dec <- dataset_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec %>%
count(decade, sort = TRUE)
spotify_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced |>
select(features, decade_group) |>
rename(decade = decade_group) |>
mutate(decade = as.factor(decade)) |>
na.omit()
split <- initial_split(df, prop = 0.8, strata = decade)
train <- training(split)
test <- testing(split)
# Fit model
rf_model <- randomForest(decade ~ ., data = train)
# Predict
pred <- predict(rf_model, newdata = test)
# Accuracy
mean(pred == test$decade)
reticulate::repl_python()
