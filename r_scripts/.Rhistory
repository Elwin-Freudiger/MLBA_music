kable() %>%
kable_styling()
spotify_num <- dataset_clean %>%
select_if(is.numeric) %>%
na.omit()
corrplot(cor(spotify_num), method = "color", type = "upper", tl.cex = 0.7)
#start by selecting numeric columns
num_dataset <- dataset_clean %>%
select_if(is.numeric)
cor_matrix <- cor(num_dataset, use = "complete.obs")
ggcorrplot(
cor_matrix,
method    = "square",
lab       = TRUE,
lab_size  = 2,
tl.cex    = 10,
colors    = c("blue", "white", "red"),
outline.col = "gray80",
) +
labs(
title = "Correlation Matrix for Song features"
) +
xlab(NULL)+ ylab(NULL)+
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
#adding a histogram with songs by year
year_hist <- dataset_clean %>%
select(release_year) %>%
filter(release_year>0) %>%
ggplot(aes(x=release_year)) +
geom_histogram(binwidth = 1, fill="blue", color="black") +
theme_minimal() +
labs(title = "Number of songs by release year", x="Year")
year_hist
#year_hist %>% ggplotly()
track_dens <- dataset_clean %>%
filter(track_number!=0) %>%
ggplot(aes(x=track_number)) +
geom_histogram(fill='blue', color='black') +
theme_minimal() +
labs(title = "Track number density", y="Density", x="track number")
track_dens
benford_distr <- data.frame(
first_digit = 1:9,
benford_pct = log10(1 + 1/(1:9)) * 100
)
benford <- dataset_clean %>%
filter(track_number!=0) %>%
mutate(first_digit = as.numeric(substr(as.character(track_number), 1, 1))) %>%
ggplot(aes(x = first_digit)) +
geom_histogram(
bins = 9,
fill = "blue",
color = "black",
aes(y = after_stat(count / sum(count) * 100))
) +
geom_line(
data = benford_distr,
aes(x = first_digit, y = benford_pct),
color = "red",
size = 1
) +
scale_x_continuous(breaks = 1:9) +
labs(
title = "First Digit Distribution of Track Numbers vs Benford's Law",
x = "First Digit",
y = "Percentage"
) +
theme_minimal()
benford
year_tracknum <- dataset_clean %>%
filter(release_year!=0,
track_number!=0) %>%
ggplot(aes(x=release_year, y=track_number)) +
geom_point(color = "blue", size = 2) +
theme_minimal()  +
labs(title="Track number depending on the release year", y="Track Number", x="Release Year")
year_tracknum
duration_hist <- dataset_clean %>%
drop_na() %>%
mutate(duration_ms = duration_ms/1000) %>%
ggplot(aes(x=duration_ms)) +
geom_histogram(bins=50, fill='blue', color='black') +
theme_minimal() +
labs(title ="Histogram of track durations", x="Track Duration (s)")
duration_hist
median_year <- dataset_clean %>%
drop_na() %>%
group_by(release_year) %>%
summarise(median_duration = median(duration_ms, na.rm = TRUE)) %>%
mutate(median_duration = median_duration/1000) %>%
ggplot(aes(y=median_duration, x=release_year))+
geom_line(color='blue', size=1) +
theme_minimal()+
labs(title="Evolution of median track duration by year", y="Median Duration (s)", x="Year")
median_year
duration_pop <- dataset_clean %>%
drop_na() %>%
mutate(duration_ms = duration_ms/1000) %>%
ggplot(aes(y=duration_ms, x=popularity)) +
geom_point(color="blue")
duration_pop
explicit_year <- dataset_clean %>%
drop_na() %>%
group_by(release_year, is_explicit) %>%
summarise(count = n(), .groups = "drop") %>%
ggplot(aes(x = release_year, y = count, fill = as.factor(is_explicit))) +
geom_area(position = "fill", alpha=0.6) +
scale_fill_manual(
values = c("TRUE" = "red", "FALSE" = "lightgray"),
name = "Explicit",
labels = c("FALSE" = "Non-Explicit", "TRUE" = "Explicit")
) +
labs(
title = "Evolution of Explicit vs. Non-Explicit Songs",
x = "Year",
y = "Share",
fill = "Explicit"
) +
scale_y_continuous(labels = scales::percent) +
theme_minimal()
explicit_year
line_explicit <- dataset_clean %>%
drop_na() %>%
group_by(release_year) %>%
summarise(
total = n(),
explicit_count = sum(is_explicit, na.rm = TRUE),
explicit_share = explicit_count / total
) %>%
ggplot(aes(x = release_year, y = explicit_count)) +
geom_line(color = "blue", size = 1) +
labs(
title = "Share of Explicit Songs Over Time",
x = "Year",
y = "Share of Explicit Songs"
) +
theme_minimal()
line_explicit
explicit_boxplot <- dataset_clean %>%
drop_na() %>%
ggplot(aes(x = as.factor(is_explicit), y = popularity)) +
geom_boxplot() +
labs(
title = "Popularity by Explicit Status",
x = "Explicit",
y = "Popularity"
) +
theme_minimal()
explicit_boxplot
explicit_popdate <- dataset_clean %>%
drop_na() %>%
ggplot(aes(x = release_year, y = popularity, color=as.factor(is_explicit))) +
scale_color_manual(
values = c("TRUE" = "red", "FALSE" = "blue"),
name = "Explicit",
labels = c("FALSE" = "Non-Explicit", "TRUE" = "Explicit")
) +
geom_point() +
labs(
title = "Popularity by year with explicit status",
x = "Release Year",
y = "Popularity"
) +
theme_minimal()
#+ facet_wrap(vars(is_explicit))
explicit_popdate
# Summary statistics for key numeric features
dataset_clean %>%
select(track_name, artist_names, popularity) %>%
arrange(desc(popularity)) %>%
head() %>%
kable() %>%
kable_styling()
avg_pop_date <- dataset_clean %>%
drop_na() %>%
group_by(release_year) %>%
summarise(avg_pop = mean(popularity, na.rm = TRUE)) %>%
ggplot(aes(y=avg_pop, x=release_year))+
geom_line(color='blue', size=1) +
theme_minimal()+
labs(title="Evolution of mean popularity by year", y="Popularity", x="Year")
avg_pop_date
# Separate multiple artists
top_artists <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
count(artist_names, sort = TRUE) %>%
slice_head(n = 30)
# Plot
artist_bar <- ggplot(top_artists, aes(x = reorder(artist_names, n), y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(
title = "Top 30 Artists by Song Count",
x = "Artist",
y = "Number of Songs"
) +
theme_minimal()
artist_bar
artist_pop <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
group_by(artist_names) %>%
summarise(avg_pop = mean(popularity, na.rm = TRUE)) %>%
arrange(desc(avg_pop)) %>%
slice_head(n=10) %>%
kable() %>%
kable_styling()
artist_pop
artist_len <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
group_by(artist_names) %>%
summarise(avg_time = mean(duration_ms, na.rm = TRUE)) %>%
arrange(desc(avg_time)) %>%
slice_head(n=10) %>%
kable() %>%
kable_styling()
artist_len
artist_len_inc <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
group_by(artist_names) %>%
summarise(avg_time = mean(duration_ms, na.rm = TRUE)) %>%
arrange(avg_time) %>%
slice_head(n=10) %>%
kable() %>%
kable_styling()
artist_len_inc
top_genres <- dataset_clean %>%
mutate(artist_genres = replace_na(artist_genres, "No genre")) %>%
filter(!is.na(artist_genres)) %>%
mutate(artist_genres = str_split(artist_genres, ",")) %>%
unnest(artist_genres) %>%
mutate(artist_genres = str_trim(artist_genres)) %>%
count(artist_genres, sort = TRUE) %>%
slice_head(n = 20)
# Plot
genre_bar <- ggplot(top_genres, aes(x = reorder(artist_genres, n), y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(
title = "Top 20 Genres by Song Count",
x = "Genre",
y = "Number of Songs"
) +
theme_minimal()
genre_bar
genre_pop <- dataset_clean %>%
mutate(artist_genres = replace_na(artist_genres, "No genre")) %>%
filter(!is.na(artist_genres)) %>%
mutate(artist_genres = str_split(artist_genres, ",")) %>%
unnest(artist_genres) %>%
mutate(artist_genres = str_trim(artist_genres)) %>%
group_by(artist_genres) %>%
summarise(avg_pop= mean(popularity, na.rm = TRUE)) %>%
arrange(desc(avg_pop)) %>%
slice_head(n=10) %>%
kable() %>%
kable_styling()
genre_pop
clustering_data <- dataset_clean %>%
select(c(where(is.numeric), is_explicit)) %>%
select(-c(release_year)) %>%
drop_na() %>%
scale()
fviz_nbclust(clustering_data,
kmeans,
method='wss',
k.max = 100,
verbose = FALSE)
song_km <- kmeans(clustering_data, centers=30)
song_comp <- data.frame(clustering_data,
Clust=factor(song_km$cluster),
Id=row.names(dataset_clean))
song_df <- melt(song_comp, id=c("Id", "Clust"))
head(song_df, 10)
ggplot(song_df, aes(y=value, group=Clust, fill=Clust)) +
geom_boxplot() +
facet_wrap(~variable)
song_distances <- dist(clustering_data, method = "manhattan")
song_melt <- melt(as.matrix(song_distances))
head(song_melt)
song_hc <- hclust(song_distances, method="complete")
plot(song_hc, hang=-1)
rect.hclust(song_hc, k=13)
song_clust_hc <- cutree(song_hc, k=13)
song_clust_hc
# 1. Prepare numeric data and keep release_year for color
pca_data <- dataset_clean %>%
filter(release_year>0) %>%
drop_na() %>%
select(c(danceability, energy, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo)) %>%
scale()
# 2. Run PCA on everything except release_year
pca_result <- prcomp(pca_data, scale. = TRUE)
# 3. Extract PCA scores and add release year for coloring
pca_scores <- as.data.frame(pca_result$x[, 1:2])
release_years <- dataset_clean %>%
filter(release_year > 0) %>%
drop_na() %>%
pull(release_year)
pca_scores$release_year <- release_years
# 4. Extract loading for arrows
loadings <- as.data.frame(pca_result$rotation[, 1:2])
loadings$variable <- rownames(loadings)
# 5. Plot PCA with arrows and color by release year
ggplot(pca_scores, aes(x = PC1, y = PC2, color = release_year)) +
geom_point(alpha = 0.6) +
scale_color_viridis_c(option = "plasma") +
geom_segment(data = loadings,
aes(x = 0, y = 0, xend = PC1 * 5, yend = PC2 * 5),  # arrows, scaled
arrow = arrow(length = unit(0.2, "cm")), color = "gray30") +
geom_text(data = loadings,
aes(x = PC1 * 5.3, y = PC2 * 5.3, label = variable),
size = 3, color = "gray20") +
labs(
title = "PCA Biplot of Song Features",
x = "PC1",
y = "PC2",
color = "Release Year"
) +
theme_minimal()
pca_data <- dataset_clean %>%
filter(release_year>0) %>%
drop_na() %>%
select(c(danceability, energy, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo)) %>%
scale()
songs_pca <- PCA(pca_data, ncp = 11, graph = FALSE)
songs_pca
pca_data <- dataset_clean %>%
filter(release_year>0) %>%
drop_na() %>%
select(c(danceability, energy, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo)) %>%
scale()
songs_pca <- PCA(pca_data, ncp = 11, graph = FALSE)
songs_pca
fviz_pca_var(songs_pca)
fviz_contrib(songs_pca, choice = "var", axes = 1)
fviz_pca_biplot(songs_pca)
fviz_eig(songs_pca, addlabels = TRUE, ncp=11)
library(gridExtra)
p1 <- fviz_pca_biplot(songs_pca, axes = 1:2)
p2 <- fviz_pca_biplot(songs_pca, axes = 3:4)
p3 <- fviz_pca_biplot(songs_pca, axes = 5:6)
grid.arrange(p1, p2, p3, nrow = 2, ncol=2)
spotify_year <- dataset_clean |>
mutate(
year = as.numeric(substr(release_date, 1, 4)),
decade = floor(year / 10) * 10
)
spotify_dec  <- spotify_year |>
count(decade, sort = TRUE)
spotify_cleaned <- spotify_dec %>%
filter(decade != 0)
spotify_grouped <- spotify_cleaned %>%
mutate(
decade_group = case_when(
decade %in% c(1950, 1960) ~ "1950–1960",
TRUE ~ as.character(decade)
)
)
spotify_grouped %>%
count(decade_group, sort = TRUE)
# Trouver la taille du plus petit groupe
min_n <- spotify_grouped |>
count(decade_group) |>
summarise(min_n = min(n)) |>
pull(min_n)
# Échantillonnage équilibré
spotify_balanced <- spotify_grouped |>
group_by(decade_group) |>
slice_sample(n = min_n) |>
ungroup()
spotify_balanced %>%
count(decade_group, sort = TRUE)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
colnames(spotify_balanced) <- tolower(colnames(spotify_balanced))
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
names(spotify_balanced) <- tolower(names(spotify_balanced))
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
names(spotify_balanced) <- tolower(names(spotify_balanced))
print(colnames(spotify_balanced))
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_balanced %>%
select(all_of(features), decade_group) %>%
rename(decade = decade_group) %>%
mutate(decade = as.factor(decade)) %>%
na.omit()
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$decade)
print(accuracy)
# Confusion Matrix
confusionMatrix(pred, test$decade)
spotify_binary <- spotify_year |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
spotify_binary <- spotify_year |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
spotify_binary <- spotify_year |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
spotify_clean <- dataset_clean |>
mutate(year = as.numeric(substr(release_date, 1, 4)))
# Calculate and display the median
median_year <- median(spotify_dec$year, na.rm = TRUE)
print(median_year)
spotify_binary <- spotify_clean |>
mutate(
after_median = if_else(year > median(year, na.rm = TRUE), "after", "before"),
after_median = as.factor(after_median)
)
features <- c("danceability", "energy", "acousticness", "instrumentalness",
"liveness", "loudness", "speechiness", "tempo", "valence", "duration_ms")
df <- spotify_binary |>
select(all_of(features), after_median) |>
na.omit()
set.seed(123)
train_idx <- sample(seq_len(nrow(df)), size = 0.8 * nrow(df))
train <- df[train_idx, ]
test <- df[-train_idx, ]
rf_model <- randomForest(after_median ~ ., data = train, ntree = 500)
# Predictions
pred <- predict(rf_model, newdata = test)
# Accuracy
accuracy <- mean(pred == test$after_median)
print(accuracy)
# Confusion Matrix
library(caret)
confusionMatrix(pred, test$after_median)
# Separate multiple artists
top_artists <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
count(artist_names, sort = TRUE) %>%
slice_head(n = 30)
# Plot
artist_bar <- ggplot(top_artists, aes(x = reorder(artist_names, n), y = n)) +
geom_bar(stat = "identity", fill = "steelblue") +
coord_flip() +
labs(
title = "Top 30 Artists by Song Count",
x = "Artist",
y = "Number of Songs"
) +
theme_minimal()
artist_bar
artist_len <- dataset_clean %>%
filter(!is.na(artist_names)) %>%
mutate(artist_names = str_split(artist_names, ",")) %>%
unnest(artist_names) %>%
mutate(artist_names = str_trim(artist_names)) %>%
group_by(artist_names) %>%
summarise(avg_time = mean(duration_ms, na.rm = TRUE)) %>%
arrange(desc(avg_time)) %>%
slice_head(n=10) %>%
kable() %>%
kable_styling()
artist_len
