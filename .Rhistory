# Faceted boxplots with individual y-axis scales
ggplot(long_data, aes(x = "", y = Value)) +
geom_boxplot() +
facet_wrap(~ Variable, scales = "free_y") +
labs(title = "Boxplots for Numeric Variables (Individual Scales)", x = "", y = "") +
theme_minimal()
# Summary statistics for key numeric features
spotify_clean %>%
select_if(is.numeric) %>%
summary() %>%
kable() %>%
kable_styling()
spotify_num <- spotify_clean %>%
select_if(is.numeric) %>%
na.omit()
corrplot(cor(spotify_num), method = "color", type = "upper", tl.cex = 0.7)
spotify_clean$year <- as.numeric(substr(spotify_clean$`release_date`, 1, 4))
# Fit a linear regression model to predict the year
mod_year <- lm(year ~ danceability + energy + loudness + tempo + valence + acousticness +
instrumentalness + liveness + speechiness,
data = spotify_clean)
# Summary of the model
summary(mod_year)
# Filter relevant features and remove missing values
spotify_rf <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness",
"instrumentalness", "liveness", "speechiness", "popularity", "duration_ms", "artist_genres")]
# Remove rows with missing values
spotify_rf <- na.omit(spotify_rf)
set.seed(42)  # For reproducibility
rf_model <- randomForest(year ~ .,
data = spotify_rf,
ntree = 500,
importance = TRUE)
print(rf_model)
# Variable importance
importance(rf_model)
varImpPlot(rf_model)
# Predict on training data
pred_rf <- predict(rf_model)
# RMSE
rmse_rf <- sqrt(mean((spotify_rf$year - pred_rf)^2))
cat("Random Forest RMSE:", round(rmse_rf, 2), "\n")
set.seed(42)
n <- nrow(spotify_rf)
id_train <- sample(1:n, 0.8 * n)
train <- spotify_rf[id_train, ]
test <- spotify_rf[-id_train, ]
rf_model <- randomForest(year ~ ., data = train, ntree = 500, importance = TRUE)
pred_test <- predict(rf_model, newdata = test)
rmse_test <- sqrt(mean((test$year - pred_test)^2))
cat("Test RMSE:", round(rmse_test, 2))
# Scatterplot of actual vs predicted
plot(test$year, pred_test,
xlab = "Actual Year", ylab = "Predicted Year",
main = "Predicted vs Actual on Test Set")
abline(0, 1, col = "red")  # ideal prediction line
install.packages("rpart")
install.packages("rpart.plot")
install.packages("rpart")
install.packages("rpart.plot")
#| echo: false
#| message: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(broom)
library(reshape2)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(magrittr)
library(corrplot)
library(plotly)
library(randomForest)
library(rpart)
library(rpart.plot)
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
# Predict on test set
pred_tree <- predict(tree_model, newdata = test)
# Predict on test set
pred_tree <- predict(tree_model, newdata = test)
# View complexity parameter table
printcp(tree_model)
# Visualize CP plot
plotcp(tree_model)
# Prune the tree at the optimal CP
tree_pruned <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"])
# Plot the pruned tree
rpart.plot(tree_pruned, type = 2, extra = 101, main = "Pruned Regression Tree")
pred_pruned <- predict(tree_pruned, newdata = test)
# Your regression-ready dataset (already cleaned and encoded)
spotify_rt <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness", "instrumentalness",
"liveness", "speechiness", "popularity", ,
"duration_ms", "artist_genres")]
#train and split
set.seed(42)
n <- nrow(spotify_rt)
#| echo: false
#| message: false
library(knitr)
library(tidyverse)
library(kableExtra)
library(broom)
library(reshape2)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(magrittr)
library(corrplot)
library(plotly)
library(randomForest)
library(rpart)
library(rpart.plot)
#| echo: false
spotify <- read_csv("~/ML project/top_10000_1950-now.csv")
dim(spotify)
#| echo: false
# Preview the dataset
knitr::kable(head(spotify),
format = "markdown",
align = 'c',
table.attr = 'class="table table-bordered"',
row.names = FALSE) %>%
kable_styling(font_size = 10, full_width = FALSE, position = "center")
spotify <- spotify |>
rename(
track_uri            = `Track URI`,
track_name           = `Track Name`,
artist_uris          = `Artist URI(s)`,
artist_names         = `Artist Name(s)`,
album_uri            = `Album URI`,
album_name           = `Album Name`,
album_artist_uris    = `Album Artist URI(s)`,
album_artist_names   = `Album Artist Name(s)`,
release_date         = `Album Release Date`,
album_image_url      = `Album Image URL`,
disc_number          = `Disc Number`,
track_number         = `Track Number`,
duration_ms          = `Track Duration (ms)`,
preview_url          = `Track Preview URL`,
is_explicit          = `Explicit`,
popularity           = `Popularity`,
isrc                 = `ISRC`,
added_by             = `Added By`,
added_at             = `Added At`,
artist_genres        = `Artist Genres`,
danceability         = `Danceability`,
energy               = `Energy`,
key                  = `Key`,
loudness             = `Loudness`,
mode                 = `Mode`,
speechiness          = `Speechiness`,
acousticness         = `Acousticness`,
instrumentalness     = `Instrumentalness`,
liveness             = `Liveness`,
valence              = `Valence`,
tempo                = `Tempo`,
time_signature       = `Time Signature`,
album_genres         = `Album Genres`,
label                = `Label`,
copyrights           = `Copyrights`
)
spotify_vr <- spotify |>
select(-artist_uris, -album_uri,-album_artist_uris,-album_artist_names, -disc_number,-preview_url, -isrc, -added_by, -added_at, -album_genres, -copyrights,-key)
ncol(spotify_vr)
library(dplyr)
library(stringr)
spotify_vr <- spotify_vr |>
mutate(track_uri = str_extract(track_uri, "[^:]+$"))
#| echo: false
# Preview the dataset
knitr::kable(head(spotify_vr),
format = "markdown",
align = 'c',
table.attr = 'class="table table-bordered"',
row.names = FALSE) %>%
kable_styling(font_size = 10, full_width = FALSE, position = "center")
# Count total missing values
sum(is.na(spotify_vr))  # This will return the total number of NAs
# Show missing values per column
colSums(is.na(spotify_vr))
#Rows with missing values
rows_with_missing <- spotify_vr |>
filter(if_any(everything(), ~ is.na(.) | . == ""))
# View the rows
rows_with_missing
spotify_clean <- spotify_vr |>
filter(!is.na(loudness) & loudness != "")
colSums(is.na(spotify_clean))
numeric_data <- spotify_clean %>% select(where(is.numeric)) |>
select(-mode,-time_signature)
long_data <- pivot_longer(numeric_data, cols = everything(), names_to = "Variable", values_to = "Value")
# Faceted boxplots with individual y-axis scales
ggplot(long_data, aes(x = "", y = Value)) +
geom_boxplot() +
facet_wrap(~ Variable, scales = "free_y") +
labs(title = "Boxplots for Numeric Variables (Individual Scales)", x = "", y = "") +
theme_minimal()
# Summary statistics for key numeric features
spotify_clean %>%
select_if(is.numeric) %>%
summary() %>%
kable() %>%
kable_styling()
spotify_num <- spotify_clean %>%
select_if(is.numeric) %>%
na.omit()
corrplot(cor(spotify_num), method = "color", type = "upper", tl.cex = 0.7)
spotify_clean$year <- as.numeric(substr(spotify_clean$`release_date`, 1, 4))
# Fit a linear regression model to predict the year
mod_year <- lm(year ~ danceability + energy + loudness + tempo + valence + acousticness +
instrumentalness + liveness + speechiness,
data = spotify_clean)
# Summary of the model
summary(mod_year)
# Filter relevant features and remove missing values
spotify_rf <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness",
"instrumentalness", "liveness", "speechiness", "popularity", "duration_ms", "artist_genres")]
# Remove rows with missing values
spotify_rf <- na.omit(spotify_rf)
set.seed(42)  # For reproducibility
rf_model <- randomForest(year ~ .,
data = spotify_rf,
ntree = 500,
importance = TRUE)
print(rf_model)
# Variable importance
importance(rf_model)
varImpPlot(rf_model)
# Predict on training data
pred_rf <- predict(rf_model)
# RMSE
rmse_rf <- sqrt(mean((spotify_rf$year - pred_rf)^2))
cat("Random Forest RMSE:", round(rmse_rf, 2), "\n")
set.seed(42)
n <- nrow(spotify_rf)
id_train <- sample(1:n, 0.8 * n)
train <- spotify_rf[id_train, ]
test <- spotify_rf[-id_train, ]
rf_model <- randomForest(year ~ ., data = train, ntree = 500, importance = TRUE)
pred_test <- predict(rf_model, newdata = test)
rmse_test <- sqrt(mean((test$year - pred_test)^2))
cat("Test RMSE:", round(rmse_test, 2))
# Scatterplot of actual vs predicted
plot(test$year, pred_test,
xlab = "Actual Year", ylab = "Predicted Year",
main = "Predicted vs Actual on Test Set")
abline(0, 1, col = "red")  # ideal prediction line
# Your regression-ready dataset (already cleaned and encoded)
spotify_rt <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness", "instrumentalness",
"liveness", "speechiness", "popularity", ,
"duration_ms")]
# Extraire le premier genre depuis artist_genres
spotify_clean$main_genre <- sapply(strsplit(as.character(spotify_clean$artist_genres), ",\\s*"), `[`, 1)
# Nettoyer et convertir
spotify_clean$is_explicit <- as.factor(spotify_clean$is_explicit)
spotify_clean$main_genre <- as.factor(spotify_clean$main_genre)
# Créer le dataset utilisé pour la régression
spotify_rt <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness", "instrumentalness",
"liveness", "speechiness", "popularity", "is_explicit",
"duration_ms", "main_genre")]
spotify_rt <- na.omit(spotify_rt)
#train and split
set.seed(42)
n <- nrow(spotify_rt)
id_train <- sample(1:n, 0.8 * n)
train <- spotify_rt[id_train, ]
test <- spotify_rt[-id_train, ]
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
# Prédire
pred_tree <- predict(tree_model, newdata = test)
# RMSE
rmse_tree <- sqrt(mean((test$year - pred_tree)^2))
cat("CART Test RMSE:", round(rmse_tree, 2), "\n")
# View complexity parameter table
printcp(tree_model)
# Visualize CP plot
plotcp(tree_model)
# Prune the tree at the optimal CP
tree_pruned <- prune(tree_model, cp = tree_model$cptable[which.min(tree_model$cptable[,"xerror"]),"CP"])
# Plot the pruned tree
rpart.plot(tree_pruned, type = 2, extra = 101, main = "Pruned Regression Tree")
pred_pruned <- predict(tree_pruned, newdata = test)
rmse_pruned <- sqrt(mean((test$year - pred_pruned)^2))
cat("Pruned Tree Test RMSE:", round(rmse_pruned, 2), "\n")
rpart.plot(tree_model,
type = 2,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 2,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = FALSE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 2,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 0,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 4,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 4,         # Show feature names and predictions
extra = 1,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 4,         # Show feature names and predictions
extra = 105,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 4,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 4,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = TRUE,    # Do not print split condition below the node
faclen = 0)
rpart.plot(tree_model,
type = 2,         # Show feature names and predictions
extra = 101,      # Show number of obs + mean in terminal nodes
fallen.leaves = TRUE,
box.palette = "Blues",
tweak = 1.2,
branch.lty = 1,
shadow.col = "gray",
under = FALSE,    # Do not print split condition below the node
faclen = 0)
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 3, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 1, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 1.5, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 1,5, extra = 101, main = "Regression Tree - Year")
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
# Extraire le premier genre depuis artist_genres
spotify_clean$main_genre <- sapply(strsplit(as.character(spotify_clean$artist_genres), ",\\s*"), `[`, 1)
# Nettoyer et convertir
spotify_clean$is_explicit <- as.factor(spotify_clean$is_explicit)
spotify_clean$main_genre <- as.factor(spotify_clean$main_genre)
# Créer le dataset utilisé pour la régression
spotify_rt <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness", "instrumentalness",
"liveness", "speechiness", "popularity", "is_explicit",
"duration_ms")]
spotify_rt <- na.omit(spotify_rt)
#train and split
set.seed(42)
n <- nrow(spotify_rt)
id_train <- sample(1:n, 0.8 * n)
train <- spotify_rt[id_train, ]
test <- spotify_rt[-id_train, ]
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
# Extraire le premier genre depuis artist_genres
spotify_clean$main_genre <- sapply(strsplit(as.character(spotify_clean$artist_genres), ",\\s*"), `[`, 1)
# Nettoyer et convertir
spotify_clean$is_explicit <- as.factor(spotify_clean$is_explicit)
spotify_clean$main_genre <- as.factor(spotify_clean$main_genre)
# Créer le dataset utilisé pour la régression
spotify_rt <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness", "instrumentalness",
"liveness", "speechiness", "popularity", "is_explicit")]
spotify_rt <- na.omit(spotify_rt)
#train and split
set.seed(42)
n <- nrow(spotify_rt)
id_train <- sample(1:n, 0.8 * n)
train <- spotify_rt[id_train, ]
test <- spotify_rt[-id_train, ]
#fit the regression tree
tree_model <- rpart(year ~ .,
data = train,
method = "anova",
control = rpart.control(cp = 0.01))
# Plot the tree
rpart.plot(tree_model, type = 2, extra = 101, main = "Regression Tree - Year")
# Filter relevant features and remove missing values
spotify_rf <- spotify_clean[, c("year", "danceability", "energy", "loudness",
"tempo", "valence", "acousticness",
"instrumentalness", "liveness", "speechiness", "popularity", "duration_ms", "artist_genres")]
# Remove rows with missing values
spotify_rf <- na.omit(spotify_rf)
set.seed(42)  # For reproducibility
rf_model <- randomForest(year ~ .,
data = spotify_rf,
ntree = 500,
importance = TRUE)
print(rf_model)
